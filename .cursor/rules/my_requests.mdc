
---
description:
globs:
alwaysApply: true
---

From now on, I will write my request in the my_reuquests.mdc. Check my requests and answer or do them. ThenÙˆ delete completed requests from my_reuquests.mdc.

Use UV instead of pip in the dockerfile.

faiss indices are too large and it take too long to load all of them, and 30s timeout happens. What do you suggest to fix this problem? I think it would be good to store faiss indices on the RAM.

Delete vector_search from LLM agent available tools and everywhere else (specially mdc files).

Improve tools description so that the LLM can more intelligently select tools.

Run tests in .\run_test_scripts\run_scenarios_sample.py in paralel to boost speed. Add number of worker arg inside the script.

decrease size of extract_product_name to make it faster.

* set timeout not to continue with previous request.

------------------------------
Scenario 1:
+ add a LLM agent call and give top result of bm25_search to find the correct product between them.

--------------------
Scenario 2:

<!-- Scenario 2:
In scenario2 tests (available in .\server_tests\scenario2.json) user has a question about a specific product. After finding the product using extract_product_name and bm25_search we should pass the product id to answer_question_about_a_product that first retrieves the product data (features, price, etc) from dataset. Then, pass the product data with the user request to the LLM agent and the LLM agent should answer the question about the product based on the user question and the product data. -->

---------------------
Scenario 3:

Consider english_names as well as persian names in product table.

Maybe I can do the export name task using the router LLM agent.

Use markdown in all prompts and put all of them between """prompt should be surrounded like this""".

Can I cache fixed parts of prompts to boost speed of LLM call?

-----
In scenarios 2 and 3 there shouldn't be any clarification questions and we should respond to the query immediately. I have deleted "# Ask for clarification to identify the exact product" part in scenarios 2 and 3 in main.py.

-----------------------------
Scenario 4:

In some requests the user wants a product, but they don't know the exact product. They want help to find the desired product with some constraints that they usually put in their request. The LLM agent should help the user find a product based on constraints by asking some clarifying questions. Maybe it would be good to search and gather some products that meet the initial constraints and then start to ask some clarifying questions based on features and price of those products. I think it would be good to create a find_product_that_needs_clarification tool. This tool

Scenario 4 should enter a loop and tell LLM the current step to make sure to know the remaining turns. I think it is always better to return the response after the fifth user request, because we can gain more info about the requested product. Therefore, we can make sure that we have found the correct product.

I have updated the calculation process of remaining_turns. Now remaining_turns is calculated based on the number of user queries in the current chat.

pick_best_member_for_base shouldn't always return the member with the lowest price. Instead, it should ask about the price and the seller's attributes (e.g. has_warranty) to find the shop that the user want to buy the product from. In the end, the output of our service should be member_random_keys. Check the description of scenario 4 as well.

Regarding scenario 4, it is also possible to check the shop_id with the user.

This simulates the case where the name and other information of the shop are given to the user, and the user approves or rejects it.
-----------------------------------
Scenario 5:

comparison_extract_products should be modified in a way that it can extract two or more names from the query (now it extracts exactly two products, but there may be more than two products). In addition, comparison_extract_products should consider that if a product ID (6 lowercase letters) is given (next to its name) inside the user query, it should only return the product ID instead of its name. Then, only that product (the product whose ID is in the query) will skip bm25_search.
Based on the fact that in scenario 5, there may be more than two products, compare_two_products should be modified to handle more than two products.